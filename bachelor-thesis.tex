\documentclass[times]{itmo-student-thesis}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - languages={...} - устанавливает перечень используемых языков. По умолчанию это {english,russian}.
%%                     Последний из языков определяет текст основного документа.

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}


%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

% \lstloadlanguages{Haskell}

\lstdefinelanguage{Haskell}{}

%% Делает кавычки в листингах прямыми.
\usepackage{fontspec}
\lstset{basicstyle=\addfontfeature{Mapping=no-mapping-ligtex}}

%% Добавляет абзацные отсупы для параграфов в списках кроме первого параграфа
\usepackage{enumitem}
\setlist{listparindent=\parindent, nosep}

%% Указываем файл с библиографией.
\addbibresource{bachelor-thesis.bib}

\begin{document}
\studygroup{M34351}
\title{Разработка библиотеки комбинаторных парсеров высшего порядка нечувствительных к левой рекурсии}
\author{Ступников Александр Сергеевич}{Ступников А.С.}
\supervisor{Забашта Алексей Сергеевич}{Забашта А.С.}{доцент., к.т.н.}{главный научный сотрудник Университета ИТМО}
\publishyear{2024}
% %% Дата выдачи задания. Можно не указывать, тогда надо будет заполнить от руки.
% \startdate{01}{сентября}{2024}
% %% Срок сдачи студентом работы. Можно не указывать, тогда надо будет заполнить от руки.
% \finishdate{31}{мая}{2024}
% %% Дата защиты. Можно не указывать, тогда надо будет заполнить от руки.
% \defencedate{15}{июня}{2024}

\addconsultant{Булычев Д.Ю.}{канд. физ.-мат. наук, доцент}

\secretary{Штумпф С.А.}

%% Задание TODO
%% Аннотация TODO

%% Эта команда генерирует титульный лист и аннотацию.
\maketitle{Бакалавр}

%% Список определений
\startdefinitionspage

\begin{enumerate}
    \item \makedefinition[язык]{Формальный язык}{множество конечных слов (строк, цепочек) над конечным алфавитом}

    \item \textbf{Формальная грамматика}~(англ. \textit{formal grammar})~--- способ описания формального языка, 
        представляющий собой четверку
    
        $\Gamma =\langle \Sigma, N, S \in N, P \subset ((\Sigma \cup N)^* N (\Sigma \cup N)^*) \times (\Sigma\cup N)^{*}\rangle$, где:
        \begin{itemize}
            \item \makedefinition{$\Sigma$}{алфавит, элементы которого называют \textbf{терминалами} (англ. \textit{terminals})}
            \item \makedefinition{$N$}{множество, элементы которого называют \textbf{нетерминалами} (англ. \textit{nonterminals})}
            \item \makedefinition{$S$}{начальный символ грамматики (англ. \textit{start symbol})}
            \item \makedefinition{$P$}{набор правил вывода (англ. \textit{production rules} или \textit{productions}) $\alpha\rightarrow \beta$}
        \end{itemize}

    \item \makedefinition[КСГ, англ. \textit{сontext-free grammar}]{Контекстно-свободная грамматика}{грамматика, у которой в 
        левых частях всех правил стоят только одиночные нетерминалы}

    \item \makedefinition[КС язык, англ. \textit{context-free language}]{Контекстно-свободный язык}{язык, задаваемый контекстно-свободной грамматикой}

    \item \makedefinition[разбор, парсинг, англ. \textit{parsing}]{Синтаксический анализ}{процесс сопоставления линейной последовательности 
        лексем (слов, токенов) формального языка с его формальной грамматикой}

    \item \makedefinition[парсер, англ. \textit{parser}]{Синтаксический анализатор}{программа, производящая ситанксический анализ}

    \item \makedefinition[англ. \textit{recogniser}]{Рекогнайзер}{программа, определяющая, принадлежит ли строка формальному языку}

    \item \makedefinition{Семантика языка}{это смысловое значение конструкций языка. (функция, сопоставляющую строку, 
        принадлежащую языку, некоторому значению)}
        
    \item \makedefinition[ввод]{Входной поток}{линейная последовательность токенов, которая передаётся парсеру для разбора}
    
    \item \makedefinition{LL(k) грамматика}{грамматика, при разборе которой на основании $k$ токенов входного потока 
        можно однозначно определить правило вывода, которое необходимо применить}

    \item \makedefinition[англ. \textit{backtracking}]{Поиск с возвратом}{техника, при которой парсер возвращает поток ввода в 
        исходное состояние после попытки разбора каждого правила при разборе нетерминала}

    \item \makedefinition{Longest мatch first}{принцип проектирования парсера, при котором правило, 
        при разборе которой способно поглотиться наибольшее число символов входного потока, должно быть опробовано первым при разборе нетерминала языка}

    \item \makedefinition{Lookahead}{число символов входного потока, которое парсер учитывает при выборе правила в 
        рамках разбора нетерминала}

    \item \makedefinition[англ. \textit{domain-specific language}, \textit{DSL}]{Предметно-ориентированный язык}{формальный язык, специализированный для конкретной 
        области применения}

    \item \makedefinition[англ. \textit{continuation}, \textit{DSL}]{Продолжение}{абстрактное представление состояния 
        программы в определённый момент, которое может быть сохранено и использовано для перехода в это состояние; 
        в качестве продолжений можно использовать функции}

    \item \makedefinition[англ. \textit{Continuation Passing Style}, \textit{CPS}]{Стиль передачи продолжения}{это стиль 
        программирования, в котором функции вместо возвращения значений передают контроль продолжениям, которые определяют,
        что случится далее}

\end{enumerate}

%% Оглавление
\tableofcontents

%% Макрос для введения. Совместим со старым стилевиком.
\startprefacepage
\textbf{Актуальность работы}

Различных формальных языков становится всё больше, при этом многие такие языки имеют схожие структуры. В связи с этим
возникает необходиомость писать комбинируемые парсеры, чтобы иметь возможность разбивать их на части и переиспользовать для
разных языков. Это позволило бы ускорить время разработки парсеров для схожих формальных языков. Кроме того такой
подход дал бы возможность разбивать крупные парсеры для сложных формальных языков на небольшие части, удобные для
долгосрочной поддержки и развития.

\textbf{Цель работы}

Добиться возможности переиспользовать части парсеров.

\textbf{Задача работы}

Создание библиотеки комбинаторных парсеров, обладающих следующими свойствами:

\begin{enumerate}
    \item Распознавание любой однозначной контекстно-свободной грамматики.
    \item Нечувствительность к longest match first.
    \item Нечувствительность к левой рекурсии.
    \item Полиномиальное время работы.
\end{enumerate}

\textbf{Структура работы}

\begin{enumerate}
    \item В Главе 1 представлено описание предметной области.
    \item В Главе 2 представлен обзор существующих подходов, описание выбранного подхода, детали реализации решения.
    \item В Главе 3 представлена верификация полученных результатов, даны примеры практического применения 
    разработанного подхода.
\end{enumerate}

%% Начало содержательной части.
\chapter{ОБЗОР ПРЕДМЕТНОЙ ОБЛАСТИ}

В этой главе даётся введение в область синтаксического анализа формальных языков, разбираются принятые подходы и приёмы, 
использующиеся при построении парсеров.

\section{Подходы к синтаксическому анализу}\label{sec:parsing_approaches}

Для выполнения синтаксического анализа используют парсеры. По сути парсер это функция из некоторого состояния в
список пар из изменённого состояния и результата, то есть функция $S \rightarrow (R \times S)^*$, где $S$
--- множество состояний, $R$ --- множество результатов. На практике состоянием обычно является поток
некоторых символов или токенов, а результатом --- дерево разбора. Есть несколько подходов к написанию парсеров. Самый
наивный --- ручное написание парсера, например, с помощью нисходящего рекурсивного спуска. Такой подход позволяет
строить производительные и тонко настраиваемые парсеры, однако, как правило, не подходит для разбора произвольных КСГ,
а также значительно увеличивает время и сложность разработки программы синтаксического анализа. Одним из более
продвинутых подходов является использование генераторов парсеров (таких как Bison\cite{bison} или
ANTLR\cite{antlr}), которые создают парсер на основе описания грамматики путём использования некоторого
предметно-ориентированного языка. Другим продвинутым подходом является использование комбинаторных парсеров, которые
представляют из себя функции, путём композиции которых пользователь неявно задаёт грамматику и семантику языка, анализ
которого будет производиться.

\section{Преимущества комбинаторных парсеров}\label{sec:parser_combinators_advantages}

Традиционно для крупных языков программирования используют генераторы парсеров, так как они за счёт выполнения
статического анализа грамматики имеют меньшее время работы. Такое время работы также достигается за счёт того, что
генераторы парсеров работают как правило только с $LL(k)$ грамматиками. Следует заметить, что такие
грамматики однозначны.

Напротив, комбинаторные парсеры зачастую способны работать с любыми контекстно-свободными грамматиками, однако при этом
имеют полиномиальное или даже экспоненциальное относительно длины ввода время работы на некоторых грамматиках и входных
данных.

Крайне важной чертой, отличающей  комбинаторные парсеры от генераторов парсеров, является интегрированность первых в
язык программирования, на котором написан парсер. Это означает, что комбинаторные парсеры, являясь обычными функциями,
написаны на языке компилятора. Это позволяет получить такие преимущества, как, например, проверка типов на этапе
компиляции парсера. Кроме того такая интегрированность позволяет писать комбинаторные парсеры более абстрактно, отходя
от деталей грамматики и семантики конкретного языка программирования. Комбинаторные парсеры можно объединять
произвольным образом, а части описания этих парсеров переиспользовать.

\section{Cуществующие практические реализации комбинаторных парсеров и их проблемы}\label{sec:current_parser_combinators_problems}

Простейшая реализация комбинаторного парсера использует backtracking, чтобы иметь неограниченный lookahead и, как
следствие, возможность разбирать произвольные КСГ. Однако использование backtracking может приводить к
экспоненциальному времени разбора некоторых слов для ряда грамматик. Например, рассмотрим грамматику на
рис.~\ref{exp_grammar}.

\begin{figure}[!h]
\caption{Грамматика c экспоненциальной сложностью}\label{exp_grammar}
\[
    \begin{array}{lll}
        A & \to & xAa      \\
          &     & xAb      \\
          &     & \epsilon
    \end{array}
\]
\end{figure}

На вводах типа \lstinline[language=Haskell]{"xxxxbbbb"} (которые можно записать регулярным выражением $x^nb^n$) cложность разбора
в соответствии с грамматикой на рис.~\ref{exp_grammar} растёт экспоненциально с ростом $n$.
Действительно, при раскрытии нетерминала $A$ парсер с backtracking сначала пытается применить первое
правило, то есть $A \to xAa$. При этом на вводах типа $x^nb^n$ при раскрытии
$A$ всегда необходимо применять второе правило. Получается, что парсер как бы перебирает в
лексикографическом порядке все строки вида $x^n(a|b)^n$ для некоторого $n$, притом строка
$x^nb^n$ будет проверена последней, а значит, парсер сделает число шагов равное числу строк вида
$x^n(a|b)^n$ минус 1, то есть для заданного $n$ парсер сделает $2^{n-1}$ шагов.

Во избежание экспоненциального времени работы некоторые практические реализации комбинаторных парсеров могут делать
backtracking, только если пользователь явно укажет, что он необходим при разборе правила некоторого нетерминала (так
делает megaprsec\cite{megaparsec} с помощью кобинатора try). Это позволяет достигнуть линейного времени работы,
однако использование этого подхода приводит к тому, что парсеры приходится писать с учётом longest match first, что не
позволяет разбирать неоднозначные грамматики, а также приводит к невозможности описать любую КСГ. Это плохо само по
себе, однако ещё хуже то, что следствием этого является невозможность комбинировать такие парсеры, ведь при
произвольном объединении грамматик путём композирования функций-парсеров longest match first может перестать
соблюдаться. Например, при объединении грамматик, состоящих из нетерминалов $A$ и
$B$ с рис.~\ref{uncomposable_grammar}, путём задания парсера для нетерминала $C$ строку
\lstinline|"somebody"| нельзя будет полностью распознать, потому что её префикс \lstinline|"some"| будет поглощён правилом
$A \to some$, хотя грамматика из нетерминала $B$ способна поглотить весь поток ввода.

\begin{figure}[!h]
    \caption{Неправильное объединение парсеров}\label{uncomposable_grammar}
    \[
        \begin{array}{lll}
            A & \to & anybody \\
              &     & some  \\
            B & \to & somebody \\
              &     & any  \\
            C & \to & A  \\
              &     & B
        \end{array}
    \]
\end{figure}

Другим подходом, позволяющим комбинаторным парсерам с backtracking работать за время меньшее, чем экспоненциальное,
является использование мемоизации. Причина экспоненциального времени работы парсеров с backtracking (как в том числе
можно видеть из примера c рис.~\ref{exp_grammar}) заключается в том, что одна и та же часть ввода разбирается
парсером несколько раз. Такого поведения можно избежать путём запоминания промежуточных результатов разбора парсера.
При использовании комбинаторного парсера любой нетерминал грамматики является функцией, которая принимает поток ввода и
возвращает список пар из изменённого состояния и результата. Например, парсер для нетерминала $A \to aA | eps$ на
строке \lstinline{"aaa"} вернёт \lstinline{[("aaa", "")("aa", "a"), ("a", "aa"), ("", "aaa")]}. Для мемоизации парсера
$A$ необходимо завести таблицу, в которую при первом вызове парсера $A$ на
\lstinline{"aaa"} добавится запись о том, что для ввода \lstinline{"aaa"} парсер должен вернуть
\lstinline{[("aaa", "")("aa", "a"), ("a", "aa"), ("", "aaa")]}. При последующих вызовах парсера $A$ на \lstinline{"aaa"}
будет возвращаться мемоизированный результат. При условии возможности находить хэш частей входного потока и сравнивать
их за константное время, эта операция выполняется за константное время. Следует заметить, что подход с мемоизацией
обладает теми же свойствами, что и хорошо известный алгоритм Эрли\cite{norvig_techniques_1991} за исключением того факта, что
мемоизированные парсеры не могут быть записаны леворекурсивно. Как следствие, мемоизированные парсеры с backtracking
способны разбрирать любую КСГ за полиномиальное время.

Тем не менее большинство мемоизированных комбинаторных парсеров с backtracking ограничены в том, как их можно
комбинировать между собой. Особенно это касается комбинаторных парсеров высшего порядка, которые на основе одних
парсеров создают другие. Одной из проблем является невозможность большинства комбинаторных парсеров завершаться при
разборе леворекурсивных грамматик.

\section{Левая рекурсия}\label{sec:left_recursion}

Левая рекурсия возникает, когда для разбора нетерминала грамматики необходимо разобрать этот же нетерминала. 

\begin{figure}[!h]
    \caption{Леворекурсивная грамматика}\label{leftrec_grammar}
    \[
        \begin{array}{lll}
            E & \to & E+E \\
              &     & t
        \end{array}
    \]
\end{figure}

Грамматику и семантику некоторых языков гораздо удобнее описывать с использованием левой рекурсии. Кроме того
левая рекурсия может возникнуть при использовании комбинаторных парсеров высшего порядка. Рассмотрим пример из листинга 
\ref{lst:higher_order_left_rec}.

\begin{lstlisting}[float=!h,caption={Возникновение левой рекурсии},label={lst:higher_order_left_rec}]
    seq (x, y) = x ";" y
    stmt = seq (stmt, stmt) | VAR ":=" EXPR
\end{lstlisting}

Сам по себе парсер \lstinline{seq} нелеворекурсивен, однако при вызове его с \lstinline{stmt} в качестве первого аргумента возникает левая рекурсия.
Этот нарочито простой пример показывает, как левая рекурсия может неожиданным образом возникнуть при использовании
парсеров высшего порядка.

Таким образом одно из главных преимуществ комбинаторных парсеров, заключающееся в их композиционности, остаётся
раскрытым не до конца в случае, когда леворекурсивные грамматики не могут быть разобраны парсером.

\section{Типы комбинаторных парсеров}\label{sec:parser_combinators_types}

Для написания комбинаторных парсеров обычно используют одну из двух абстракций: \textbf{монаду}~(англ.
\textit{monad})	или \textbf{аппликатив}~(англ. \textit{applicative}). Парсеры, которые используют эти
абстракции называют соответственно  \textbf{монадическими} и \textbf{апликативными}. Можно заметить, что тип любого
парсера (то есть $S \rightarrow (S \times R)^*$),  принадлежит к классу монад\cite{hutton_monadic_nodate}. Монадические парсеры
являются подмножеством апликативных, то есть с помощью монадического парсера всегда можно закодировать аппликативный.
Монадические парсеры обладают большей выразительной мощью, чем аппликативные, что позволяет с их помощью описывать не
только	    контекстно-свободные грамматики. Однако эта мощь приводит к тому, что структуру монадических парсеров
невозможно анализировать статически, что нельзя сказать об аппликативных парсерах. В листинге \ref{lst:non_context_free}
приведён пример монадического парсера,	который парсит слова из не контекстно-свободного языка, задаваемого множеством
слов $\{a^nb^nc^n \mid n \in \mathbb{N}\}$. Заметим, что структура парсера \lstinline{anbncn} формируется во время работы
программы, а не на этапе компиляции, и зависит от количества символов \lstinline{'a'}, которое присутсвует в
начале разбираемой строки.

\begin{lstlisting}[language=Haskell,float=!h,caption={Класс монад в Haskell},label={lst:monad_typeclass}]
    class Monad m where
        return :: a -> m a
        (>>=) :: m a -> (a -> m b) -> m b
\end{lstlisting}

\begin{lstlisting}[language=Haskell,caption={Класс аппликативов в Haskell},label={lst:applicative_typeclass}]
    class Applicative f where
        (<$>) :: (a -> b) -> f a -> f b
        pure :: a -> f a
        (<*>) :: f (a -> b) -> f a -> f b
\end{lstlisting}

\begin{lstlisting}[language=Haskell,caption={Монадический парсер для не КС языка},label={lst:non_context_free}]
    anbncn :: Parser String String
    anbncn = do
        a <- some (char 'a')
        b <- replicate (length a) (char 'b')
        c <- replicate (length a) (char 'c')
        return (a ++ b ++ c)
\end{lstlisting}

\chapterconclusion

В этой главе были описаны основные подходы к созданию инструментов синтаксического анализа. Были разобраны тонкости реализации 
комбинаторных парсеров.

\chapter{ПРЕДЛАГАЕМЫЙ ПОДХОД}

В этой главе сначала даётся обзор существующих решений, которые потенциально могут решать задачу, поставленную в рамках 
работы, рассматриваются недостатки существующих решений. Далее предлагается собственное решение, разбираются детали его
практической реализации.

\section{Существующие решения}\label{sec:existing_solutions}

На текущий момент есть несколько решений, которые частично выполняют задачу, поставленную рамках работы. А именно есть
несколько алгоритмов синтаксического анализа, позволяющих разбирать любые леворекурсивные контекстно-свободные грамматики с
использованием комбинаторных парсеров. Рассмотрим их подробнее.

\textbf{Использование длины остатка ввода}~(Frost (2008)\cite{hudak_parser_2008})

Данный подход использует длину оставшегося ввода и специальный контекст для подсчёта количества леворекурсивных вызовов, которое
было сделано в некоторой ветви разбора. Если количество леворекурсивных вызовов превышает оставшуюся длину ввода, ветвь разбора
завершается с пустым результатом. Для обеспечения полиномиального времени работы используется мемоизация. Главным недостаткамом данного 
подхода является асимптотика $O(n^4)$ для леворекурсивных грамматик. Для всех остальных грамматик асимптотика --- $O(n^3)$. Кроме
того для работы данного подхода необходимо знать длину ввода.

\textbf{Cancellation разбор}~(Nederhof (1994)\cite{nederhof_linguistic_1994})
    
Данный подход использует "cancellation set", который хранит посещённые в текущей ветке разбора нетерминалы. C помощью "cancellation set"
можно можно отслеживать леворекурсивные вызовы нетерминалов и успешно их проводить. Недостатком разбора является $O(e^n)$ время работы,
а также необходимость измения грамматики, путём добавления специльных нетерминалов, которые ответствены за работу с "cancellation set".
TODO надо подробнее разобраться с этим подходом

\textbf{Леворекурсивный разбор PEG}~(Warth (2008)\cite{warth_packrat_2008})

PEG --- это особый вид грамматик, которые могут быть разобраны за линейное время с использованием алгоритма
Packrat\cite{ford_parsing_nodate}. Оригинальный алгоритм не способен работать с левой рекурсией, тем не менее в него можно
добавить поддержку леворекурсивных парсеров с помощью процесса под названием "grow the seed"\cite{warth_packrat_2008}, в
рамках которого леворекурсивная цепочка правил применяются к потоку ввода много раз до тех пор, пока это применение
закончивается успешно. Данная модификация сохраняет линейное время работы алгоритма. 

Такое время работы достигается в алгоритме Packrat с помощью использования мемоизации, а также за счёт особенностей
PEG. В частности того факта, что PEG локально и глобально однозначны в отличие от КСГ, которые могут быть локально
неоднозначными даже при условии глобальной однозначности.

Недостаток этого подхода заключается в том, что в PEG привычная операция альтерации между правилами нетерминалов не
является симметричной. Например, грамматика $A \leftarrow aa / a$ не эквивалетна $A \leftarrow a / aa$ (в PEG вместо
"$|$"{} принято писать "$/$"{}, а вместо "$\to$"{} писать "$\leftarrow$"):
на вводе \lstinline{"ab"} парсер для $A \leftarrow ab / b$ должен вернуть \lstinline{"ab"}, а парсер для
$A \leftarrow b / ab$ вернуть \lstinline{"a"}, потому что правило $A \leftarrow aa$ не будет применено к вводу,
так как первое завершилось успешно. Другими парсеры для PEG не делают backtracking, потому что само описание PEG делает
это невозможным. В связи с этим парсеры для PEG должны быть написаны с учётом longest match first, что не позволяет их
комбинировать.

\textbf{Разбор в стиле передачи продолжений или CPS}~(Johnson (1995)\cite{johnson_memoization_nodate})

Джонсон предлагает подход к написанию рекогнайзеров с использованием мемоизированных продолжений. Оказывается, что
рекогнайзеры, полученные путём	применения этого подхода нечувствительны к левой рекурсии, а также имеют время работы
$O(n^3)$. К сожалению, в оригинальный работе приводится способ строить только рекогнайзеры, но не парсеры.
Следствием этого является использование множеств для хранения результатов разбора в оригинальной работе, что приводит к
необходимости уметь сравнивать такие результаты, а также искать их хэш за константу. Это не проблема для рекогнайзеров,
где результатом является длина разобранного префикса ввода, однако для парсеров такое требование неприемлемо, ведь при
работе с ними пользователь сам определяет тип результата, для которого не всегда возможно написать константную по
времени реализацию сравнения и поиска хэша. Тем не менее для однозначных грамматик подход, использованный в
оригинальный работе можно расширить на парсеры, в том числе монадические комбинаторные парсеры.

Для достижения цели, поставленной в работе, было принято решение взять за основу CPS рекогнайзеры и усовершенствовать их.
В следующем разделе сначала будет рассмотрено, что такое стиль передачи продолжения в целом, далее будет описана Cont монада,
после этого её мемоизированная версия. Наконец, будет показано, как создать парсер с помощью мемоизированной Cont монады.

\section{Отсроченные комбинаторные парсеры или DPC}\label{sec:deferred_parsers}

Отсроченные парсеры (англ. deferred parser combinators, DPC) --- это оригинальный подход, который был изучен в рамках
работы. Несмотря на то, что не получилось с его помощью построить парсеры, обладающие необходимомыми свойства, кажется
нужным рассказать о DPC, хотя бы в силу их необычности. TODO дописать, возможно вынести в appendix

\section{Стиль передачи продолжения (CPS)}\label{sec:cps}

Для написания реализованной в рамках ВКР библиотеки был выбран язык программирования Haskell. Haskell является функциональным языком, 
с чистыми функциями. Разберёмся, как устроен стиль передачи продолжения в подобном языке. Рассмотрим пример кода из листинга 
\ref{lst:pythagoras} для рассчёта квадрата гипотенузы треугольника\cite{noauthor_haskellcontinuation_nodate} по теореме Пифагора.

\begin{lstlisting}[language=Haskell,float=!h,caption={Теорема Пифагора},label={lst:pythagoras}]
    add :: Int -> Int -> Int
    add x y = x + y

    square :: Int -> Int
    square x = x * x

    pythagoras :: Int -> Int -> Int
    pythagoras x y = add (square x) (square y)
\end{lstlisting}

Чтобы записать тот же код в CPS стиле необходимо, чтобы функции \lstinline[language=Haskell]{add}, 
\lstinline[language=Haskell]{square} и \lstinline[language=Haskell]{pythagoras} вместо \lstinline[language=Haskell]{Int}
возвращали функцию, которая принимает продолжение и возвращает результат, эту функцию будем называть \textit{отложенным вычислением}. Тип такой функции \lstinline[language=Haskell]{(Int -> r) -> r}, 
то есть само продолжение имеет тип \lstinline[language=Haskell]{Int -> r}. Код, переписанный в стиле передачи продолжения, 
представлен на листинге \ref{lst:pythagoras_cps}. Можно сказать, что теперь все функции принимают дополнительный аргумент 
с типом \lstinline[language=Haskell]{Int -> r}, который является продолжением.

\begin{lstlisting}[language=Haskell,float=!h,caption={Теорема Пифагора в CPS},label={lst:pythagoras_cps}]
    add_cps :: Int -> Int -> ((Int -> r) -> r)
    add_cps x y = \k -> k (add x y)
    
    square_cps :: Int -> ((Int -> r) -> r)
    square_cps x = \k -> k (square x)
    
    pythagoras_cps :: Int -> Int -> ((Int -> r) -> r)
    pythagoras_cps x y = \k ->
        square_cps x $ \x_squared ->
        square_cps y $ \y_squared ->
        add_cps x_squared y_squared $ k
\end{lstlisting}

Теперь, чтобы получить результат вычислений, например, для треугольника с катетами 3 и 4, можно вызвать \lstinline[language=Haskell]{pythagoras_cps 3 4 id}.

\section{Монада Cont}\label{sec:cps_monad}

Пусть мы хотим последовательно соединить два
отложенных вычисления \lstinline[language=Haskell]{(a -> r) -> r} и \lstinline[language=Haskell]{(b -> r) -> r}. 
Притом второе вычисление мы будет составлять на основе первого. Функция для этого представлена на листинге \ref{lst:cps_bind}.

\begin{lstlisting}[language=Haskell,float=!h,caption={Соединение отложенных вычислений},label={lst:cps_bind}]
    chainCPS :: ((a -> r) -> r) -> 
        (a -> ((b -> r) -> r)) -> 
        ((b -> r) -> r)
    chainCPS s f = \k -> s $ \x -> f x $ k
\end{lstlisting}


Заметим, что если заменить \lstinline[language=Haskell]{(a -> r) -> r} на \lstinline[language=Haskell]{m a}, а 
\lstinline[language=Haskell]{(b -> r) -> r} на \lstinline[language=Haskell]{m b}, то функция \lstinline[language=Haskell]{chainCPS}
по сути будет являться монадлическим \lstinline[language=Haskell]{bind}.

Разовьём эту идею, добавив новый тип c листинга \ref{lst:cont_type}.

\begin{lstlisting}[language=Haskell,float=!h,caption={Тип Cont},label={lst:cont_type}]
    newtype Cont r a = Cont { 
        runCont :: (a -> r) -> r 
        }
\end{lstlisting}

По сути тип \lstinline[language=Haskell]{Cont} --- это обёртка над функцией \lstinline[language=Haskell]{(a -> r) -> r}.
Этот тип является монадой, что показано на листинге \ref{lst:cont_monad}.

\begin{lstlisting}[language=Haskell,float=!h,caption={Инстанс Monad для Cont},label={lst:cont_monad}]
    instance Monad (Cont r) where
        return x = Cont ($ x)
        s >>= f  = Cont $ \c -> runCont s $ 
                    \x -> runCont (f x) c
\end{lstlisting}

\section{Полиморфизм по результату}\label{sec:poly_cont_monad}

Недостаток Cont монады с листинга \ref{lst:cont_type} заключается в том, что тип результата (то есть
\lstinline{r}) должен оставаться  неизменным внутри монады. Это означает, что при \lstinline{bind} нельзя изменить
тип результа монады, что не позволяет, например, при описании парсеров соединять через \lstinline{bind} парсеры,
возвращающие разные по типу результаты. Чтобы это испрвить нужно, чтобы тип результата определялся не типом
\lstinline{Cont}, а типом продолжения \lstinline{a -> r}. Для этого воспользуемся экзистенциальными типами из Haskell.
Обновленная версия типа \lstinline{Cont}, которая полиморфна по результату, а также инстанс монады для неё
представлен  на листинге \ref{lst:poly_cont_monad}. Можно заметить, что инстанс для монады не изменился.

\begin{lstlisting}[language=Haskell,float=!h,caption={Монада Cont полиморфная по результату},label={lst:poly_cont_monad}]
    newtype Cont a = Cont
        { runCont :: forall r. (a -> r) -> r
        }

    instance Monad (Cont r) where
        return x = Cont ($ x)
        s >>= f  = Cont $ \c -> runCont s $ 
                    \x -> runCont (f x) c
\end{lstlisting}

\section{Продолжения с состоянием}\label{sec:stateful_cont}

Для написания мемоизированного парсера в стиле CPS необходимо, чтобы отложенные вычисления использовали таблицу мемоизации. 
Такая таблица мемоизации является по сути изменяемым состоянием. Для его реализации можно воспользоваться State монадой.
Тогда тип Cont монады необходимо изменить. Изменённый тип представлен на листинге \ref{lst:stateful_cont_type}.

\begin{lstlisting}[language=Haskell,float=!h,caption={Тип Cont с состоянием},label={lst:stateful_cont_type}]
    newtype Cont r a = Cont { 
        runCont :: forall r. (a -> State MemoTable r) 
            -> State MemoTable r 
        }
\end{lstlisting}

Теперь продолжения имеют тип \lstinline{a -> State MemoTable r} и могут использовать таблицу мемоизации для вычисления результата.
Класс Monad для нового типа продолжений определяется так же, как на листинге \ref{lst:poly_cont_monad}.

\section{Недетерминированный Cont}\label{sec:contt_transformer}

В результате работы парсера может получится несколько результатов или вовсе ни одного, что свидетельствует о том, что 
разбираемая строка не принадлежит языку. Поэтому отложенные вычисления в \lstinline{Cont} монаде должны возвращать не 
единственный результат (как это следовало из типа \lstinline{Cont} до сих пор), а коллекцию результатов. В качестве коллекции используем обычный список.
Снова изменим тип \lstinline{Cont}, заменив тип результата \lstinline{r} на \lstinline{[r]}. Изменённый тип представлен на листинге \ref{lst:nondeterministic_cont_type}.
Важно заметить, что изменённый тип принадлжит классу Alternative.

\begin{lstlisting}[language=Haskell,float=!h,caption={Недетерминированный Cont с состоянием},label={lst:nondeterministic_cont_type}]
    newtype Cont r a = Cont { 
        runCont :: forall r. (a -> State MemoTable [r]) 
            -> State MemoTable [r] 
        }

    instance Alternative (Cont k s) where
        empty :: Cont k s a
        empty = Cont (\_ -> return empty)
        (<|>) :: Cont k s a -> Cont k s a -> Cont k s a
        (<|>) a b =
        Cont
            ( \k -> do
                r1 <- runCont a k
                r2 <- runCont b k
                return $ r1 <|> r2
            )
\end{lstlisting}

\section{Парсеры в CPS стиле}\label{sec:cps_parser}

Теперь с использование разработанного в секции \ref{sec:contt_transformer} продолжения, несложно написать парсер в стиле 
передачи продолжения. Как уже было замечено ранее парсер --- это функция типа \lstinline{s -> [(r, s)]}, где \lstinline{s} --- это
тип потока ввода, а \lstinline{r} --- тип результата разбора. Если возвращаемый список пустой, то разбираемая строка не принадлежит
языку, если возвращаемый список содержит более одного элемента, то строка может быть разобрана несколькими способами.
На самом деле парсер не обязан возвращать список. Например, вместо списка парсер может возвращать Maybe (листинг \ref{lst:maybe}).
В этом случае его тип --- \lstinline{s -> Maybe (r, s)}. Парсер с таким типом может возвращать \lstinline{Nothing}, если разбор 
закончился неудачно, или \lstinline{Just (r, s)}, если разбор завершился успехом. Заметим, что такой парсер не может вернуть 
несколько результатов разбора. Побробнее с этим можно ознакомится в рамках работы \cite{hutton_monadic_nodate}.

\begin{lstlisting}[language=Haskell,float=!h,caption={Недетерминированный Cont с состоянием},label={lst:maybe}]
    data Maybe a = Just a | Nothing
\end{lstlisting}

Такая независимость парсера от "контейнера" для результата наводит на мысль написать обобщённый тип парсера,
параметризированный относительно типа такого "контейнера": \lstinline {type ParserT m s r = s -> m (r, s)}. Полученный
тип это в точности соответствует монадическому трансформеру \lstinline{StateT} из Haskell (листинг \ref{lst:stetet}). При условии, что	тип
\lstinline{m} принадлежит в классу монад тип \lstinline{StateT} также принадлежит к классу монад. 

\begin{lstlisting}[language=Haskell,float=!h,caption={StateT трансформер монад},label={lst:stetet}]
    newtype StateT s m a = StateT (s -> m (a, s))
\end{lstlisting}

Получается, что любой парсер монадический парсер с типом ввода \lstinline{s} и типом результата \lstinline{r} можно
записать, как \lstinline{StateT s m r}, где \lstinline{m} --- это некоторый тип принадлежащий классу монад. Как можно 
было заметить на примере со списком (\lstinline{[]}) и \lstinline{Maybe}, тип \lstinline{m} определяет свойства парсера. 
Так получилось, что тип Cont из секции \ref{sec:contt_transformer} является монадой, а значит значения с типом
\lstinline{StateT s Cont r} являются монадическими парсерами. Такие монадические парсеры мы будем называть \textbf{парсеры
в стиле CPS}. Введём для них тип с именем Parser, как на листинге \ref{lst:cps_parser}. Тип результата
\lstinline{r} опущен, чтобы kind полученного типа был \lstinline{* -> *} и \lstinline{Parser} принадлежал к
классу монад (в Haskell частично параметризованные алиасы для типов не поддерживаются).

\begin{lstlisting}[language=Haskell,float=!h,caption={Парсер в CPS стиле},label={lst:cps_parser}]
    type Parser s = StateT s Cont
\end{lstlisting}

\chapterconclusion

В этой главе были проанализированы существующие решения.

\chapter{ПОЛУЧЕННЫЕ РЕЗУЛЬТАТЫ}

В этой главе рассматриваются результаты, полученные в рамках второй главы. В том числе время работы полученного парсера,
возможности его практического применения, а также ограничения. 


%% Макрос для заключения. Совместим со старым стилевиком.
\startconclusionpage

В данном разделе размещается заключение.

\printmainbibliography

\end{document}
